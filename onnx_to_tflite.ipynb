{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check whether the model is working or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (96, 96))\n",
    "    image = image.astype(np.float32)\n",
    "    image /= 255.0  # Normalize the image to [0, 1]\n",
    "    image = np.transpose(image, (2, 0, 1))  # Channels-first format (C,H,W)\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "def main():\n",
    "    model_path = \"/home/muhammad/.insightface/models/buffalo_l/genderage.onnx\"\n",
    "\n",
    "    providers = ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n",
    "    session = onnxruntime.InferenceSession(model_path, providers=providers)\n",
    "    image_url = \"image.jpg\"\n",
    "    image = preprocess_image(image_url)\n",
    "\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    output_name = session.get_outputs()[0].name\n",
    "    pred = session.run([output_name], {input_name: image})\n",
    "    gender = np.argmax(pred[0][0][:2])\n",
    "    age = int(np.round(pred[0][0][2]*100))\n",
    "    print(gender)\n",
    "    print(age)\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the model to tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "import tensorflow as tf\n",
    " \n",
    "onnx_model = onnx.load(\"/home/muhammad/.insightface/models/buffalo_l/genderage.onnx\")\n",
    "tf_rep = prepare(onnx_model)\n",
    "tf_rep.export_graph(\"output/model.pb\")\n",
    "\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"output/model\") # path to the SavedModel directory\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checking the tflite output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (96, 96))\n",
    "    image = image.astype(np.float32)\n",
    "    image /= 255.0  # Normalize the image to [0, 1]\n",
    "    image = np.transpose(image, (2, 0, 1))  # Channels-first format (C,H,W)\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "# Step 1: Load the TFLite Model\n",
    "tflite_model_path = 'model.tflite'\n",
    "\n",
    "# Step 2: Initialize the Interpreter\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Step 3: Prepare Input Data\n",
    "# Replace this with your own input data\n",
    "image_url = \"image.jpg\"\n",
    "image = preprocess_image(image_url)\n",
    "# input_data = np.random.rand(1, input_height, input_width, input_channels).astype(np.float32)\n",
    "\n",
    "# Step 4: Run Inference\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Set input tensor\n",
    "interpreter.set_tensor(input_details[0]['index'], image)\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()\n",
    "\n",
    "# Step 5: Process Output\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "# Process the output as needed to get the final predictions\n",
    "# For example, if it's a classification model, you might apply softmax to get probabilities.\n",
    "# For regression models, you might simply use the output as the predictions.\n",
    "gender = np.argmax(output_data[0][:2])\n",
    "age = int(np.round(output_data[0][2]*100))\n",
    "print(gender)\n",
    "print(age)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facedetection_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
